#Import packages for general python function 
import pandas as pd
import numpy as np 
import scipy 
from scipy import stats
from scipy.stats import sem
import random

#Run in parallel / timing
from joblib import Parallel, delayed
from itertools import product
import time


#Import packages for running glm
import statsmodels as sm
import statsmodels.formula.api as smf
from statsmodels.formula.api import mixedlm
from statsmodels.stats.multitest import multipletests


#import packages for graphing 
import matplotlib.pyplot as plt


'''
ANALYSIS PLAN:
1. make a dataframe containing any possible relevant information regarding decoding (accuracy, train time, time, classifier, condition)
2. analyze whether the peak decoding accuracies are significantly different from zero 
   (There should be a peak in decoding accuracy, which is what I am interested in analyzing)
3. use a linear mixed model to determine whether the peak decoding accuracies changes depending on training time and/or condition. 
    a.) If it is not significantly different between conditions, then minute changes in the brain do send enough information to the 
        whole brain to decode it as well as larger changes. This would suggest that we can study processes with minute changes.
    b.) If there is a significant difference in decoding accuracy between conditions, then there is significantly less information 
        avaliable in the whole brain signal regarding minute versus large changes. This would suggest that we may not 
        be able to study processes with minute changes.
4. Plot significance-thresholded heatmaps of temporal generalization across conditions
'''

#Make dataframe containing all the necessary values (subjects, decoding accuracy, time, classifier, cond)
#Define subjects 
subjects = [1,10,16] #1,2,3,5,10,16,17,21,34,44
#Define dataframe
df = pd.DataFrame(columns=['subject','classifier','condition','train_time','test_time','accuracy'])
#Define the input path
baseDir = '/projectsn/f_mc1689_1/cpro2_eeg/'
inputDir_base = f'{baseDir}data/results/DynamicDecoding/'#RawOrSource/classifier/cond
#Define directory input lists
dataType = 'RawSensor'
classifier = ['SVM', "LDA"]#,'SVM','Random_Forest'
conds = ['Right', 'Left', 'Hand']#add ,'Hand','Left'
peakAcc = [] #Make an empty list to add peak decoding accuracies to
#Define length of trial
nTimepoints = 494

df = pd.DataFrame(columns=['subject','accuracy','train_time','test_time','classifier','condition'])

for clasCond in classifier:
    for cond in conds:
        for subjNum in subjects:
            inputPrefix = f'_SubjectDecoding_10fold_{cond}_correctOnly_noPseudoTrials.csv'
            path = f'{inputDir_base}{dataType}/{clasCond}/{cond}/TempGen/{subjNum}{inputPrefix}'

            # Read and clean data
            raw = pd.read_csv(path, header=None).values
            acc = raw[1:, :].astype(float)  # skip row/col headers
            n_train, n_test = acc.shape
            train_t = np.linspace(-0.09, 3.855, n_train)
            test_t = np.linspace(-0.09, 3.855, n_test)
            #Subject one isnt getting encoded right!!!
            # Efficient row collection
            rows = []
            for t_train_idx, t_train in enumerate(train_t):
                for t_test_idx, t_test in enumerate(test_t):
                    rows.append({
                        'subject': subjNum,
                        'classifier': clasCond,
                        'condition': cond,
                        'train_time': t_train,
                        'test_time': t_test,
                        'accuracy': acc[t_train_idx, t_test_idx]  
                    })
                    
            df = pd.concat([df, pd.DataFrame(rows)], ignore_index=True)

#Use a linear mixed model to determine wehther classifier type or condition impacts accuracy decoding
#Fit linear mixed model with random intercepts per subjects 
#will be treating time as a categorical variable because I am not expecting a linear increase in decoding accuracy. This is to find "peaks" in the accuracy.
df['time_train'] = df['train_time'].astype(str)
df['time_test'] = df['test_time'].astype(str)

def analyzeTempGen(cond, t_train, df):
    ###Set up initial vars###
    #make empty list to put pvals of acc vs 50% into
    print(f'train timepoint is: {t_train}')
    chance = 0.5
    avg_accs = []

    # Make subdataframe containing all the test time points and specific train timepoints and conditions
    sub_df = df[(df['time_train'] == t_train) & (df['condition'] == cond)].copy()
    ###Test accuracy against 50% and save the timepoints that are significantly more accurate than chance###
    #Loop through groups of test times to find whether accuracy at each timepoint is significantly diff from chance
    test_times=[]
    pvals = []
    mean_accs = []
    for test_t, group in sub_df.groupby('test_time'):
        acc = group['accuracy'].values
        if len(acc) > 1:
            _, p = stats.ttest_1samp(acc, chance)
        else:
            p = 1.0
        #save time of pval, the pval, and the mean accuracy that goes with the pval
        test_times.append(test_t)
        pvals.append(p)
        mean_accs.append(np.mean(acc) if len(acc) > 0 else 0)

    # Apply FDR correction
    reject, pvals_corrected, _, _ = multipletests(pvals, method='fdr_bh')

    # Step 3: Build output array
    for i in range(len(test_times)):
        if reject[i]:
            avg_accs.append(mean_accs[i])
        else:
            avg_accs.append(0)

    return avg_accs

#Run it in parallel
def parallel_Right_analyzeTempGen(i, train_t, df):
    right_avg_acc = analyzeTempGen('Right', train_t, df)
    return i, np.array(right_avg_acc)
def parallel_Left_analyzeTempGen(i, train_t, df):
    left_avg_acc = analyzeTempGen('Left', train_t, df)
    return i, np.array(left_avg_acc)
def parallel_Hand_analyzeTempGen(i, train_t, df):
    hand_avg_acc = analyzeTempGen('Hand', train_t, df)
    return i, np.array(hand_avg_acc)
###RUNNING IT###
#Will have three matrices, one for each condition
#Each row will be a training timepoint
#The list that will be put into each row will be the average accuracy across subjects and decoder types (since there was not found 
## to be a significant difference in decoding accuracy across different decoders)
n_jobs = -1  # use all available cores
train_times = df['time_train'].unique()
#Time how long it takes to run in parallel
start = time.time()
#Run for condition = right
right_accs = np.zeros((len(train_times), nTimepoints))
right = Parallel(n_jobs=n_jobs)(
    delayed(parallel_Right_analyzeTempGen)(i, train_t, df)
    for i, train_t in enumerate(train_times))
# Fill in matrix
for i, acc_row in right:
    right_accs[i, :] = acc_row
end = time.time()
print(f"Elapsed time of right model running: {end - start:.2f} seconds")


#Run for condition = left
#Time how long it takes to run in parallel
start = time.time()
#Run for condition = right
left_accs = np.zeros((len(train_times), nTimepoints))
left = Parallel(n_jobs=n_jobs)(
    delayed(parallel_Left_analyzeTempGen)(i, train_t, df)
    for i, train_t in enumerate(train_times))
# Fill in matrix
for i, acc_row in left:
    left_accs[i, :] = acc_row
end = time.time()
print(f"Elapsed time of left model running: {end - start:.2f} seconds")

#Run for condition = hand
start = time.time()
hand_accs = np.zeros((len(train_times), nTimepoints))
hand = Parallel(n_jobs=n_jobs)(
    delayed(parallel_Hand_analyzeTempGen)(i, train_t, df)
    for i, train_t in enumerate(train_times))
# Fill in matrix
for i, acc_row in hand:
    hand_accs[i, :] = acc_row
end = time.time()
print(f"Elapsed time of hand model running: {end - start:.2f} seconds")

#Determine significant differences between left right and hand 
#Will run a linear mixed model, but it was too data intensive with all variables, so I will be averaging across decoderTypes, which
## were found to have insignificant differences in decoding accuracy anyway. These tests will determine which 
df_linearMixedModel = df.drop(['train_time', 'test_time','classifier'], axis=1)
# t_train_significance = {}
signif_ts = {}
def linearMixedModelAnalysis(t_train, df):
    df_train = df[df['time_train'] == t_train].copy()
    df_train['accuracy_centered'] = df_train['accuracy'] - 0.5

    model = mixedlm("accuracy_centered ~ C(time_test) + C(condition)", df_train, groups=df_train["subject"])
    result = model.fit()

    pvals = result.pvalues
    # Separate p-values
    intercept_p = pvals.get('Intercept', np.nan)
    cond_p = [p for name, p in pvals.items() if name.startswith("C(condition)")]
    time_p = [p for name, p in pvals.items() if name.startswith("C(time_test)")]

    # Apply FDR to time_test p-values
    _, time_p_corr, _, _ = multipletests(time_p, method='fdr_bh')

    # Track any significant results
    sig_times = []
    for indx, p in enumerate(time_p_corr):
        if p <= 0.05:
            sig_times.append({
                'pval': p,
                't_test': df_train['time_test'].unique()[indx]
            })

    return {
        'train_time': t_train,
        'intercept_p': intercept_p,
        'condition_p': cond_p,
        'time_p_corr': time_p_corr,
        'significant_times': sig_times
    }

#Run it in parallel
linResults = Parallel(n_jobs=n_jobs)(
    delayed(linearMixedModelAnalysis)(train_t, df_linearMixedModel)
    for train_t in train_times
)

#Run it
t_train_significance = {
    res['train_time']: res for res in linResults
}
signif_ts = {
    res['train_time']: res['significant_times'] for res in linResults if res['significant_times']
}

#Print results
print("Significant time_test values by train_time:")

for train_time, sig_list in signif_ts.items():
    for sig in sig_list:
        print(f"train_time: {train_time}, time_test: {sig['t_test']}, corrected p-value: {sig['pval']:.4f}")

#Make three graphs. Since timeseries decoding accuracy did not find a difference in decoder type accuracy, average across decoders.
## Also average across subjects. For each condition, make a heatmap that plots the accuracy at each train/test timepoint. Accuracies 
## that are not significantly greater than 50% will be set to 0. 
import os
def graphHeatMap(classify_cond, accMat):
    ##Specify graph title and saving 
    output_dir = '/projectsn/f_mc1689_1/cpro2_eeg/data/results/DynamicDecoding/RawSensor/Group_Results/'
    if classify_cond=='Left' or classify_cond=='Right':
        title = f'Temporal Generalization of {classify_cond} Hand\n Finger Decoding Accuracy'
        outfile = f'TempGen_{classify_cond}_Hand_Finger_Decoding_Accuracy_Avg_Subjects'
    elif classify_cond=='Hand':
        title = f'Temporal Generalization of Hand Decoding Accuracy'
        outfile = f'TempGen_Hand_Decoding_Accuracy_Avg_Subjects'

    ##Define graph dimensions based on number of timepoints within the session
    nTimepoints = accMat.shape[0]
    timepoints = np.linspace(-0.09, 3.855, nTimepoints)

    ##Plot heatmap of each timeseries of decoding accuracies (goes across x-axis) for each time point that decoding was trained on (each point on the y axis is a time point that the decoder was trained on)
    plt.figure(figsize=(14,9))
    plt.imshow(accMat, aspect='auto', cmap='viridis', origin='lower',
                extent=[timepoints[0], timepoints[-1], timepoints[0], timepoints[-1]])
    plt.colorbar(label='Decoding Accuracy')
    plt.xlabel('Test Timepoints', fontsize=13)
    plt.ylabel('Train Timepoints', fontsize=13)

    plt.grid()
    plt.title(title, fontsize=15)
    plt.axhline(0, color='white', linestyle='--')
    plt.axvline(0, color='white', linestyle='--')
    plt.savefig(os.path.join(output_dir, outfile))
    plt.show()
    print('Ran Temporal Generalization decoding analysis')
    
graphHeatMap('Right', right_accs)
graphHeatMap('Left', left_accs)
graphHeatMap('Hand', hand_accs)
