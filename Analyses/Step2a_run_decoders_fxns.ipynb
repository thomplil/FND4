{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce9619d-b801-43a3-8310-c0242a58e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('got through first functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e8d9313-c018-42f4-8e7a-f4204e3f84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "import h5py,pkg_resources,sys,scipy\n",
    "print('impored h5py etc')\n",
    "# import numpy as np\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.patches as patches\n",
    "# import matplotlib.image as mpimg\n",
    "# import seaborn as sns\n",
    "# import wbplot\n",
    "# from wbplot import pscalar\n",
    "# from mpl_toolkits.mplot3d import Axes3D  # This import registers the 3D projection\n",
    "# import plotly.graph_objects as go\n",
    "# # import graphviz\n",
    "# from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b42da375-d30f-4202-be04-35c939a50753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general python use\n",
    "import sys\n",
    "import os,glob,warnings,shutil\n",
    "import mne\n",
    "print('imported mne')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e94b2335-ea77-4d44-bf68-822e24ff4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "print('imported random')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f8f1b29-e945-4566-b114-1877a2bfceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "print('imported sklearn scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b479aec-98c7-4a84-a08a-ab6ef5cdfc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal, stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import math\n",
    "print('imported scipy sm and math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05aae467-d8d2-4727-ba9f-a024df56ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Decoders\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#read out matrices to files\n",
    "import io\n",
    "\n",
    "#Parallel loop\n",
    "from joblib import Parallel, delayed\n",
    "print('imported last modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef840656-18a4-4d10-bbea-3673b6854059",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timepoints = np.array([i for i in range(250)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4f8d0c6-18bf-4cad-8def-674d5d36b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "tempGenAcc = np.zeros((250,250))\n",
    "print(tempGenAcc[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3123e9b-6cb0-454b-87df-0dd79c5a95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_single_timepoint(classify_cond, subjNum,t, decoderType,decodingAnalysis):\n",
    "    cond_code, random_data_trl, folds_mat, decodingAnalysis = DecodingAcc(classify_cond, decoderType, subjNum, decodingAnalysis)\n",
    "    nTimepoints = random_data_trl.shape[2]\n",
    "    X = random_data_trl[:, :, t]\n",
    "    accuracies = []\n",
    "    for train_idx, test_idx in folds_mat:\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = random_cond_targets[train_idx], random_cond_targets[test_idx]\n",
    "        \n",
    "        # Initialize a NEW classifier each time (important!)\n",
    "        if decodingAnalysis =='SVM':\n",
    "            clf = SVC(kernel='linear')\n",
    "        elif decodingAnalysis == 'LDA':\n",
    "            clf = LinearDiscriminantAnalysis()\n",
    "        elif decodingAnalysis == 'Random_Forest':\n",
    "            clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "            \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "    return np.mean(accuracies), sem(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7893f29-2253-401f-b05b-9144a190b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to run temporal generalization \n",
    "def decode_TempGen(t_train, nTimepoints, classify_cond, subjNum, decoderType,decodingAnalysis):\n",
    "    cond_code, random_data_trl, folds_mat, decodingAnalysis = DecodingAcc(classify_cond, decoderType, subjNum, decodingAnalysis)\n",
    "    nTimepoints = random_data_trl.shape[2]\n",
    "    X_train_data = random_data_trl[:, :, t_train]\n",
    "    for t in range(nTimepoints):\n",
    "        # Extract data at time t across all trials\n",
    "        # Shape: (n_trials, n_channels) --> perform classification on a time point instead a trial\n",
    "        X = random_data_trl[:, :, t]\n",
    "        # 10-fold cross-validation\n",
    "        accuracies = []\n",
    "        for train_idx, test_idx in folds:\n",
    "            X_train, X_test = X_train_data[train_idx], X[test_idx]\n",
    "            y_train, y_test = random_cond_targets[train_idx], random_cond_targets[test_idx]\n",
    "            \n",
    "            if decodingAnalysis =='SVM':\n",
    "                clf = SVC(kernel='linear')\n",
    "            elif decodingAnalysis == 'LDA':\n",
    "                clf = LinearDiscriminantAnalysis()\n",
    "            elif decodingAnalysis == 'Random_Forest':\n",
    "                clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append(acc)\n",
    "\n",
    "        # Mean cross-validated accuracy at this timepoint\n",
    "        tempGenAcc[t_train,t]=np.mean(accuracies)\n",
    "\n",
    "    return tempGenAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa2d1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to load data\n",
    "def read_dataset(ds,k):\n",
    "    \"\"\"Reads an HDF5 dataset, resolving references and decoding properly.\"\"\"\n",
    "\n",
    "    # If it's a string dataset\n",
    "    str_info = h5py.check_string_dtype(ds.dtype)\n",
    "    if str_info is not None:\n",
    "        return ds.asstr()[()]\n",
    "\n",
    "    # If it's a compound structured array\n",
    "    if ds.dtype.names:\n",
    "        data = {}\n",
    "        for name in ds.dtype.names:\n",
    "            field = ds[name][()]\n",
    "            if np.issubdtype(field.dtype, np.bytes_):\n",
    "                data[name] = field.astype(str)\n",
    "            else:\n",
    "                data[name] = field\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    # If it's a dataset of references\n",
    "    if ds.dtype.kind == 'O':\n",
    "        refs = ds[()]\n",
    "        if refs.ndim > 0:\n",
    "            deref_data = []\n",
    "            for r in refs.flat:\n",
    "                if isinstance(r, h5py.h5r.Reference):\n",
    "                    real_obj = ds.file[r]\n",
    "                    if isinstance(real_obj, h5py.Dataset):\n",
    "                        deref_data.append(read_dataset(real_obj,k))\n",
    "                    elif isinstance(real_obj, h5py.Group):\n",
    "                        deref_data.append(load_group(real_obj,k))\n",
    "            return deref_data\n",
    "        else:\n",
    "            r = refs\n",
    "            real_obj = ds.file[r]\n",
    "            if isinstance(real_obj, h5py.Dataset):\n",
    "                return read_dataset(real_obj,k)\n",
    "            elif isinstance(real_obj, h5py.Group):\n",
    "                return load_group(real_obj,k)\n",
    "\n",
    "    # If it's a regular dataset\n",
    "    return ds[()]\n",
    "\n",
    "def load_group(group,k):\n",
    "    \n",
    "    \"\"\"Recursively loads an HDF5 group into a nested dictionary\"\"\"\n",
    "    result = {}\n",
    "    try:\n",
    "        for key, item in group.items():\n",
    "            if isinstance(item, h5py.Dataset):\n",
    "                result[key] = read_dataset(item,k)\n",
    "            elif isinstance(item, h5py.Group):\n",
    "                result[key] = load_group(item,k)\n",
    "            else:\n",
    "                print(f'Unknown item type: {type(item)}')\n",
    "    except Exception as e:\n",
    "        print(f'Error {e} occurred for file {k}')\n",
    "        result[k]=read_dataset(group,k)\n",
    "    return result\n",
    "\n",
    "def loadData(dirc, file, fileName):\n",
    "\n",
    "    \"\"\"Loads structured HDF5 data safely into nested dictionaries and DataFrames\"\"\"\n",
    "    datafile = f'{dirc}{file}'\n",
    "    result = {}\n",
    "    with h5py.File(datafile, 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        print(keys)\n",
    "        for key in keys:\n",
    "            result[key] = load_group(f[key],fileName)\n",
    "    # with h5py.File(datafile, 'r') as f:\n",
    "    #     result = load_group(f)\n",
    "    print(f'Finished loading {datafile}')\n",
    "    return result\n",
    "\n",
    "def getTrialInfoCols(df, key, mk, lNum):\n",
    "\n",
    "    \"\"\"Extracts and reorders trialinfo as necessary\"\"\"\n",
    "    col = df[key][mk][lNum]\n",
    "\n",
    "    # If it's a list of arrays\n",
    "    if isinstance(col, list):\n",
    "        # Flatten and combine them\n",
    "        new_col = []\n",
    "        for c in col:\n",
    "            if isinstance(c, np.ndarray):\n",
    "                new_col.append(c.flatten()[0])  # Assuming each c is like array([[value]])\n",
    "            else:\n",
    "                new_col.append(c)\n",
    "        return new_col\n",
    "\n",
    "    # If it's a single array\n",
    "    elif isinstance(col, np.ndarray):\n",
    "        return col.flatten()\n",
    "\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected type {type(col)} for column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b3267d-266d-4388-9fc0-9ce283e0ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecodingAcc(classify_cond, decoderType, subjNum, decodingAnalysis):\n",
    "    #Downsampling rate -- based on Nyquist\n",
    "    downsample_rate =250\n",
    "\n",
    "    #confine to correct trials only\n",
    "    correct_only = 1\n",
    "    if correct_only==1:\n",
    "        corr_suffix = 'correctOnly'\n",
    "    else:\n",
    "        corr_suffix = []\n",
    "\n",
    "    #**run after creating pseudotrials (sub-averaging trials prior to running\n",
    "    #classification to improve SNR)\n",
    "    run_pseudotrials = 0 #0 = no pseudotrial averaging, 10 = loop over 10 repetitions of pseudotrial averaging\n",
    "    avg_pseudotrials = 14 #*set number of trials within each cond to average over\n",
    "    if run_pseudotrials == 0:\n",
    "        pseu_suffix = 'noPseudoTrials'\n",
    "    else:\n",
    "        pseu_suffix = [num2str(run_pseudotrials),'PseudoTrialsAvgOver',num2str(avg_pseudotrials),'Trials']\n",
    "\n",
    "    #Set validation type --> how are you cross-validating it\n",
    "    validation_type = '10fold'\n",
    "\n",
    "    #Response lock info\n",
    "    resp_pre = 0.5\n",
    "    resp_post = 0.5\n",
    "\n",
    "    #determine values used in classification \n",
    "    if classify_cond =='Left':\n",
    "        cond_code = [1,2]\n",
    "    elif classify_cond =='Right':\n",
    "        cond_code = [3,4]\n",
    "    else:\n",
    "        cond_code=[1,2,3,4]\n",
    "\n",
    "    #Name directories and make any necessary ones\n",
    "    runFrom = 'FND4' #fnd4 or cpro2_eeg\n",
    "    dataType = 'RawSensor' #sensor or source\n",
    "\n",
    "    if runFrom =='FND4':\n",
    "        baseDir = '/home/let83/FND4/'\n",
    "    else:\n",
    "        baseDir = '/projectsn/f_mc1689_1/cpro2_eeg/'\n",
    "    output_dir = f'{baseDir}results/DynamicDecoding/{dataType}/{decoderType}/{classify_cond}/'\n",
    "    output_file = f'_SubjectDecoding_{validation_type}_{classify_cond}_{corr_suffix}_{pseu_suffix}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    files2load = ['fsample','elec','hdr','trialinfo','sampleinfo','trial','time','label','cfg']\n",
    "    for file in files2load:\n",
    "        input_dir = f'{baseDir}results/preproc1_causalFilter/sub{subjNum}/'\n",
    "        input_file = f'{file}_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat'\n",
    "        #globals()[f'left_{key}']\n",
    "        print(file)\n",
    "        \n",
    "        try:\n",
    "            if file == 'fsample':\n",
    "                fsample = loadData(input_dir,input_file, file)\n",
    "            elif file =='elec':\n",
    "                elec = loadData(input_dir,input_file, file)\n",
    "            elif file=='hdr':\n",
    "                hdr = loadData(input_dir,input_file, file)\n",
    "            elif file =='trialinfo':\n",
    "                trialinfo = loadData(input_dir,input_file, file)\n",
    "            elif file == 'sampleinfo':\n",
    "                sampleinfo = loadData(input_dir,input_file, file)\n",
    "            elif file == 'trial':\n",
    "                trial =  loadData(input_dir,input_file, file)\n",
    "            elif file=='time':\n",
    "                time = loadData(input_dir,input_file, file)\n",
    "            elif file=='label':\n",
    "                label = loadData(input_dir,input_file, file)\n",
    "                nChans = len(label['#refs#']) - 1\n",
    "            elif file =='cfg':\n",
    "                cfg = loadData(input_dir,input_file, file)\n",
    "        except Exception as e:\n",
    "            print(f'\\nERROR: file {file} had error {e}/n')\n",
    "    print('Loaded Data')\n",
    "    #Actually Define necessary files (trialinfo, sampleinfo, time, trials)\n",
    "    #Trialinfo\n",
    "    subsystems = (trialinfo['#subsystem#'])\n",
    "    ti = {'TaskCode':[],'acc':[],'resp':[],'rt':[]}\n",
    "    colNames = ['TaskCode','acc','resp','rt']\n",
    "    i=0\n",
    "    for coln in colNames:\n",
    "        ti[coln] = getTrialInfoCols(subsystems,'MCOS',2,i)\n",
    "        i+=1\n",
    "    trialinfo = pd.DataFrame(ti)\n",
    "    print('Defined trialinfo')\n",
    "    #Trials\n",
    "    trial.keys()\n",
    "    nTimepoints = 3945\n",
    "    nTrial = 360\n",
    "    trials_real = np.zeros((nTimepoints, nChans, nTrial))\n",
    "    tkeys = list(trial['#refs#'].keys()) #Each key is a trial\n",
    "    for tnum in range(360):\n",
    "        try:\n",
    "            tk = tkeys[tnum]\n",
    "            trials_real[:,:,tnum] = trial['#refs#'][tk]\n",
    "        except Exception as e:# one row should not have the right dimensions as there are 361 keys and only 360 trials\n",
    "            print(f'ERROR {e} at {tkeys[tnum]},{tnum}!!!\\n')\n",
    "    print('Defined trials')\n",
    "    #Define samples \n",
    "    samples = pd.DataFrame({'Start':sampleinfo['sampleinfo']['sampleinfo'][0],'End':sampleinfo['sampleinfo']['sampleinfo'][1]})\n",
    "    print('defined samples')\n",
    "    #Time and trialinfo need to be in the same format\n",
    "    time_df = pd.DataFrame()\n",
    "    for i in range(360):\n",
    "        newTrial = pd.DataFrame(list(time['time']['time'][i]))\n",
    "        nt = newTrial.T\n",
    "        time_df = pd.concat([time_df,nt],ignore_index=False)\n",
    "    print('Defined time')\n",
    "    \n",
    "    #Response Lock Data\n",
    "    data_resp = {'trialinfo':trialinfo,\n",
    "                 'sampleinfo':samples, \n",
    "                 'time' : time_df,\n",
    "                 'trial': []}\n",
    "    skipped_trials = []\n",
    "    resp_secs = pd.DataFrame()\n",
    "    time_new = pd.DataFrame()\n",
    "    for t in range(len(trialinfo['rt'])):\n",
    "        start_resp=(trialinfo['rt'][t]/1000)-resp_pre #RT-500\n",
    "        end_resp=(trialinfo['rt'][t]/1000)+resp_post #RT+500\n",
    "        newRow = pd.DataFrame({'Start':[start_resp], 'End':[end_resp]})\n",
    "        # print(newRow)\n",
    "        resp_secs=pd.concat([resp_secs,newRow],ignore_index=False)\n",
    "        #find start and end inds in .time (round to deal with floating point discrepancies)\n",
    "        times = time_df.iloc[t].values\n",
    "        start_ind=np.where(np.round(times, 3) == np.round(start_resp, 3))[0]\n",
    "        end_ind = np.where(np.round(times, 3) == np.round(end_resp, 3))[0]\n",
    "\n",
    "        if len(start_ind) == 0 or len(end_ind) == 0:\n",
    "            print(f\"Warning: No matching start or end index for trial {t}. Skipping trial.\")\n",
    "            skipped_trials.append(t)\n",
    "            continue  # skip trials that weren't answered\n",
    "\n",
    "        time_row = pd.DataFrame(list(np.arange(-0.5, 0.5, 0.001))).T\n",
    "        time_new = pd.concat([time_new,time_row],ignore_index=False)\n",
    "        trl = trials_real[:, :, t]  # (channels, timepoints) for each trial\n",
    "        trl = trl[start_ind[0]:end_ind[0]+1,:]  # +1 to include endpoint like MATLAB\n",
    "\n",
    "        # Append to data_resp['trial']\n",
    "        data_resp['trial'].append(trl)\n",
    "\n",
    "    # Update the time field for each trial\n",
    "    data_resp['time'] = time_new\n",
    "    print('Response locked data')\n",
    "        \n",
    "    ##Dynamic Decoding Preproc\n",
    "    # organize trial data so it is in the format (timepoints, channels) --> (n_trials, n_channels, n_timepoints)\n",
    "    data_stack = np.stack(data_resp['trial'], axis=0) \n",
    "    data_for_resample = np.transpose(data_stack, (0, 2, 1))\n",
    "\n",
    "    # resample trials\n",
    "    resampled_data = mne.filter.resample(data_for_resample, up=1, down=4, axis=-1)\n",
    "\n",
    "    # update data_resp to reflect downsampling\n",
    "    data_resp['trial'] = resampled_data\n",
    "    print(f'Downsampled data: {resampled_data.shape}')\n",
    "    \n",
    "    ##Sort trials that will be classified\n",
    "    cond_info = trialinfo[(trialinfo['acc'] == 1) & (trialinfo['resp'].isin(cond_code))].reset_index(drop=True)\n",
    "    cond_idx = cond_info.index.tolist()\n",
    "\n",
    "    if classify_cond=='Left':\n",
    "        cond_targets = cond_info[:]['resp']\n",
    "    elif classify_cond=='Right':\n",
    "        cond_targets = []\n",
    "        for i in range(len(cond_info)):\n",
    "            if cond_info.iloc[i]['resp'] == 3:\n",
    "                cond_targets.append(1)\n",
    "            elif cond_info.iloc[i]['resp'] == 4:\n",
    "                cond_targets.append(2)\n",
    "    elif classify_cond=='Hand':\n",
    "        cond_targets = []\n",
    "        for i in range(len(cond_info)):\n",
    "            if cond_info.iloc[i]['resp'] == 3:\n",
    "                cond_targets.append(1)\n",
    "            elif cond_info.iloc[i]['resp'] == 4:\n",
    "                cond_targets.append(2)\n",
    "            elif cond_info.iloc[i]['resp']==1:\n",
    "                cond_targets.append(1)\n",
    "            else:\n",
    "                cond_targets.append(2)\n",
    "    print('defined cond_targets')\n",
    "    \n",
    "    #Time lock the data\n",
    "\n",
    "    #make/organize data necessary for mne timelocking function \n",
    "    #data (trial x channels x time)\n",
    "    #is resampled_data --> no reorganization needed\n",
    "\n",
    "    #Info abt electrodes and data collection\n",
    "    print(resampled_data.shape)\n",
    "    n_channels = resampled_data.shape[1]\n",
    "\n",
    "    print(n_channels)\n",
    "    sfreq = 250  # sampling frequency after downsampling\n",
    "    ch_names = [f'EEG {i:03d}' for i in range(n_channels)]\n",
    "    #print(ch_names)\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "\n",
    "    #events (trial number x dummy col x event ID)\n",
    "    n_trials = resampled_data.shape[0]\n",
    "    events = np.column_stack((np.arange(n_trials), np.zeros(n_trials, dtype=int), np.ones(n_trials, dtype=int)))\n",
    "    #Timelock data\n",
    "    data_trl = mne.EpochsArray(resampled_data, info, events=events, event_id={'response': 1}, tmin=-0.5)\n",
    "    print(f'Resampled data, new shape: {data_trl.get_data().shape}')\n",
    "    \n",
    "    xx_cond_inds = random.sample(range(len(cond_targets)), len(cond_targets))\n",
    "    \n",
    "    #Make randomized cond targets\n",
    "    random_cond_targets = []\n",
    "    for i in xx_cond_inds:\n",
    "        random_cond_targets.append(cond_targets[i])\n",
    "    print('Randomized cond_target and its indices')\n",
    "    \n",
    "    # Loop over each randomized index\n",
    "    nTimepoints = 250\n",
    "    random_data_trl = np.zeros((len(xx_cond_inds), n_channels, nTimepoints))\n",
    "    for idx in xx_cond_inds:\n",
    "        trlData = data_trl.get_data()[idx]     # pull trial data\n",
    "        random_data_trl[idx, :, :] = trlData   # final shape = (319, 251, 250)\n",
    "    print('randomized trial order within a matrix of trial data')\n",
    "    \n",
    "    #Set up Dynamic Decoding\n",
    "    if decodingAnalysis =='SVM':\n",
    "        clf = SVC(kernel='linear')\n",
    "    elif decodingAnalysis == 'LDA':\n",
    "        clf = LinearDiscriminantAnalysis()\n",
    "    elif decodingAnalysis == 'Random_Forest':\n",
    "        clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "    \n",
    "    #Set up basic variables\n",
    "    nFolds = 10\n",
    "    nTrials = len(xx_cond_inds)\n",
    "    \n",
    "    # Set up 10-fold Stratified Cross Validation\n",
    "    cv = StratifiedKFold(n_splits=nFolds, shuffle=True, random_state=42)\n",
    "\n",
    "    # matrix to collect accuracy info\n",
    "    n_timepoints = np.array([i for i in range(250)])\n",
    "    \n",
    "    #Determine folds before entering loop\n",
    "    X = random_data_trl[:, :, 1]\n",
    "    folds_mat = []\n",
    "    for train, test in cv.split(X, random_cond_targets):\n",
    "        folds_mat.append((train,test))\n",
    "    print('Completed setup for decoding, defined train and and test folds')\n",
    "    return cond_code, random_data_trl, folds_mat, decodingAnalysis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     if decodingAnalysis=='DecodingAccuracy':\n",
    "#         nTimepoints = random_data_trl.shape[2]\n",
    "\n",
    "#         clf = SVC(kernel='linear')\n",
    "#         nFolds = len(folds_mat)  # should be 10\n",
    "\n",
    "#         # Preallocate result\n",
    "#         accuracy_timepoint = np.zeros((nTimepoints,))\n",
    "#         n_jobs = -1  # Use all CPUs\n",
    "#         avg_accuracy, sem_accuracy = Parallel(n_jobs=n_jobs)(delayed(decode_single_timepoint)(t, decoderType) for t in range(nTimepoints))\n",
    "#         print(f'Ran timeseries decoding')\n",
    "#         if classify_cond=='Left' or classify_cond=='Right':\n",
    "#             title = f'{classify_cond} Hand {decoderType} Finger Decoding\\nAccuracy of Subject {subjNum}'\n",
    "#             outfile = f'{classify_cond}_Hand_{decoderType}_Finger_Decoding_Accuracy_of_Subject{subjNum}'\n",
    "#         elif classify_cond=='Hand':\n",
    "#             title = f'Hand {decoderType} Decoding Accuracy of Subject {subjNum}'\n",
    "#             outfile = f'Hand_{decoderType}_Decoding_Accuracy_of_Subject{subjNum}'\n",
    "\n",
    "#         timepoints = np.linspace(-0.5, 0.5, nTimepoints)\n",
    "#         plt.figure()\n",
    "#         plt.plot(timepoints,avg_accuracy, color='steelblue', linewidth=2)\n",
    "#         plt.title(title, fontsize=15) \n",
    "#         plt.xlabel('Time (s)', fontsize=13)\n",
    "#         plt.ylabel('Decoding Accuracy', fontsize=13)\n",
    "#         plt.savefig(os.path.join(outputDir, outfile))\n",
    "#         plt.show()\n",
    "#         print('Plotted and saved timeseries decoding accuracy')\n",
    "#         #Save output\n",
    "#         avg_accuracy_pd = pd.DataFrame(avg_accuracy)\n",
    "#         full_path = os.path.join(output_dir, f'{subjNum}{output_file}.csv')\n",
    "#         avg_accuracy_pd.to_csv(full_path, index=False)\n",
    "# #         return avg_accuracy_pd\n",
    "#     elif decodingAnalysis == 'TempGen':\n",
    "#         tempGenAvgAcc = np.zeros((nTimepoints,nTimepoints))\n",
    "#         tempGenSemAcc = np.zeros((nTimepoints,nTimepoints))\n",
    "        \n",
    "#         # matrix to collect accuracy info\n",
    "#         n_timepoints = np.array([i for i in range(250)])\n",
    "#         tempGenAcc = np.zeros((nTimepoints,nTimepoints))\n",
    "\n",
    "#         #run temporal generalization decoding analysis in parallel\n",
    "#         n_jobs = -1  # Use all CPUs\n",
    "#         tempGenAcc[:,:] = Parallel(n_jobs=n_jobs)(delayed(decode_TempGen)(t,nTimepoints, decoderType) for t in range(nTimepoints))\n",
    "\n",
    "# #         for t_train in n_timepoints:\n",
    "# #             # Extract data at time t across all trials\n",
    "# #             X_train_data = random_data_trl[:, :, t_train]\n",
    "# #             for t in range(nTimepoints):\n",
    "# #                 # Extract data at time t across all trials\n",
    "# #                 # Shape: (n_trials, n_channels) --> perform classification on a time point instead a trial\n",
    "# #                 X = random_data_trl[:, :, t]\n",
    "# #                 # 10-fold cross-validation\n",
    "# #                 accuracies = []\n",
    "# #                 for train_idx, test_idx in folds_mat:\n",
    "# #                     X_train, X_test = X_train_data[train_idx], X[test_idx]\n",
    "# #                     y_train, y_test = random_cond_targets[train_idx], random_cond_targets[test_idx]\n",
    "\n",
    "# #                     clf.fit(X_train, y_train)\n",
    "# #                     y_pred = clf.predict(X_test)\n",
    "# #                     acc = accuracy_score(y_test, y_pred)\n",
    "# #                     accuracies.append(acc)\n",
    "\n",
    "# #                 # Mean cross-validated accuracy at this timepoint\n",
    "# #                 tempGenAvgAcc[t_train,t]=np.mean(accuracies)\n",
    "# #                 tempGenSemAcc[t_train,t]=sem(accuracies)        \n",
    "#         print('Ran TempGen decoding analysis')\n",
    "#         # Plot\n",
    "#         if classify_cond=='Left' or classify_cond=='Right':\n",
    "#             title = f'Temporal Generalization of {classify_cond} Hand\\n{decoderType} Finger Decoding Accuracy of Subject {subjNum}'\n",
    "#             outfile = f'TempGen_{classify_cond}_Hand_{decoderType}_Finger_Decoding_Accuracy_of_Subject{subjNum}'\n",
    "#         elif classify_cond=='Hand':\n",
    "#             title = f'Temporal Generalization of Hand {decoderType} Decoding Accuracy of Subject {subjNum}'\n",
    "#             outfile = f'TempGen_Hand_{decoderType}_Decoding_Accuracy_of_Subject{subjNum}'\n",
    "#         nTimepoints = tempGenAcc.shape[0]\n",
    "#         timepoints = np.linspace(-0.5, 0.5, nTimepoints)\n",
    "#         plt.figure(figsize=(8,6))\n",
    "#         #Plot matrix with matrix time points\n",
    "#         plt.imshow(tempGenAcc, aspect='auto', cmap='viridis', origin='lower',\n",
    "#                    extent=[timepoints[0], timepoints[-1], timepoints[0], timepoints[-1]])\n",
    "#         plt.colorbar(label='Decoding Accuracy')\n",
    "#         plt.xlabel('Test Timepoints',fontsize=13)\n",
    "#         plt.ylabel('Train Timepoints',fontsize=13)\n",
    "#         plt.title(title, fontsize=15)\n",
    "#         #Make a white line where the response happens\n",
    "#         plt.axhline(0, color='white', linestyle='--')\n",
    "#         plt.axvline(0, color='white', linestyle='--')\n",
    "#         plt.savefig(os.path.join(outputDir, outfile))\n",
    "#         plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5721afe6-fc0c-4619-b4e2-434f63767a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsample\n",
      "['fsample']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file fsample\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/fsample_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "elec\n",
      "['#refs#', 'elec']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/elec_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "hdr\n",
      "['#refs#', 'hdr']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/hdr_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "trialinfo\n",
      "['#refs#', '#subsystem#', 'trialinfo']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file trialinfo\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/trialinfo_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "sampleinfo\n",
      "['sampleinfo']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file sampleinfo\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/sampleinfo_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "trial\n",
      "['#refs#', 'trial']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file trial\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/trial_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "time\n",
      "['#refs#', 'time']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file time\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/time_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "label\n",
      "['#refs#', 'label']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file label\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/label_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "cfg\n",
      "['#refs#', '#subsystem#', 'cfg']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub1/cfg_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "Loaded Data\n",
      "Defined trialinfo\n",
      "ERROR could not broadcast input array from shape (2) into shape (3945,251) at a,205!!!\n",
      "\n",
      "Defined trials\n",
      "defined samples\n",
      "Defined time\n",
      "Warning: No matching start or end index for trial 340. Skipping trial.\n",
      "Response locked data\n",
      "Downsampled data: (359, 251, 250)\n",
      "defined cond_targets\n",
      "(359, 251, 250)\n",
      "251\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "359 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Resampled data, new shape: (359, 251, 250)\n",
      "Randomized cond_target and its indices\n",
      "randomized trial order within a matrix of trial data\n",
      "Completed setup for decoding, defined train and and test folds\n",
      "fsample\n",
      "['fsample']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file fsample\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/fsample_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "elec\n",
      "['#refs#', 'elec']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/elec_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "hdr\n",
      "['#refs#', 'hdr']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/hdr_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "trialinfo\n",
      "['#refs#', '#subsystem#', 'trialinfo']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file trialinfo\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/trialinfo_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "sampleinfo\n",
      "['sampleinfo']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file sampleinfo\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/sampleinfo_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "trial\n",
      "['#refs#', 'trial']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file trial\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/trial_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "time\n",
      "['#refs#', 'time']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file time\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/time_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "label\n",
      "['#refs#', 'label']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file label\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/label_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "cfg\n",
      "['#refs#', '#subsystem#', 'cfg']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub2/cfg_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "Loaded Data\n",
      "Defined trialinfo\n",
      "ERROR could not broadcast input array from shape (2) into shape (3945,255) at a,205!!!\n",
      "\n",
      "Defined trials\n",
      "defined samples\n",
      "Defined time\n",
      "Warning: No matching start or end index for trial 1. Skipping trial.\n",
      "Warning: No matching start or end index for trial 3. Skipping trial.\n",
      "Warning: No matching start or end index for trial 4. Skipping trial.\n",
      "Warning: No matching start or end index for trial 6. Skipping trial.\n",
      "Warning: No matching start or end index for trial 8. Skipping trial.\n",
      "Warning: No matching start or end index for trial 9. Skipping trial.\n",
      "Warning: No matching start or end index for trial 19. Skipping trial.\n",
      "Warning: No matching start or end index for trial 20. Skipping trial.\n",
      "Warning: No matching start or end index for trial 21. Skipping trial.\n",
      "Warning: No matching start or end index for trial 22. Skipping trial.\n",
      "Warning: No matching start or end index for trial 25. Skipping trial.\n",
      "Warning: No matching start or end index for trial 38. Skipping trial.\n",
      "Warning: No matching start or end index for trial 39. Skipping trial.\n",
      "Warning: No matching start or end index for trial 42. Skipping trial.\n",
      "Warning: No matching start or end index for trial 45. Skipping trial.\n",
      "Warning: No matching start or end index for trial 47. Skipping trial.\n",
      "Warning: No matching start or end index for trial 48. Skipping trial.\n",
      "Warning: No matching start or end index for trial 50. Skipping trial.\n",
      "Warning: No matching start or end index for trial 51. Skipping trial.\n",
      "Warning: No matching start or end index for trial 54. Skipping trial.\n",
      "Warning: No matching start or end index for trial 57. Skipping trial.\n",
      "Warning: No matching start or end index for trial 58. Skipping trial.\n",
      "Warning: No matching start or end index for trial 60. Skipping trial.\n",
      "Warning: No matching start or end index for trial 61. Skipping trial.\n",
      "Warning: No matching start or end index for trial 62. Skipping trial.\n",
      "Warning: No matching start or end index for trial 65. Skipping trial.\n",
      "Warning: No matching start or end index for trial 66. Skipping trial.\n",
      "Warning: No matching start or end index for trial 68. Skipping trial.\n",
      "Warning: No matching start or end index for trial 75. Skipping trial.\n",
      "Warning: No matching start or end index for trial 76. Skipping trial.\n",
      "Warning: No matching start or end index for trial 77. Skipping trial.\n",
      "Warning: No matching start or end index for trial 78. Skipping trial.\n",
      "Warning: No matching start or end index for trial 79. Skipping trial.\n",
      "Warning: No matching start or end index for trial 81. Skipping trial.\n",
      "Warning: No matching start or end index for trial 86. Skipping trial.\n",
      "Warning: No matching start or end index for trial 94. Skipping trial.\n",
      "Warning: No matching start or end index for trial 96. Skipping trial.\n",
      "Warning: No matching start or end index for trial 97. Skipping trial.\n",
      "Warning: No matching start or end index for trial 98. Skipping trial.\n",
      "Warning: No matching start or end index for trial 100. Skipping trial.\n",
      "Warning: No matching start or end index for trial 101. Skipping trial.\n",
      "Warning: No matching start or end index for trial 105. Skipping trial.\n",
      "Warning: No matching start or end index for trial 108. Skipping trial.\n",
      "Warning: No matching start or end index for trial 109. Skipping trial.\n",
      "Warning: No matching start or end index for trial 111. Skipping trial.\n",
      "Warning: No matching start or end index for trial 112. Skipping trial.\n",
      "Warning: No matching start or end index for trial 113. Skipping trial.\n",
      "Warning: No matching start or end index for trial 114. Skipping trial.\n",
      "Warning: No matching start or end index for trial 122. Skipping trial.\n",
      "Warning: No matching start or end index for trial 123. Skipping trial.\n",
      "Warning: No matching start or end index for trial 124. Skipping trial.\n",
      "Warning: No matching start or end index for trial 125. Skipping trial.\n",
      "Warning: No matching start or end index for trial 127. Skipping trial.\n",
      "Warning: No matching start or end index for trial 132. Skipping trial.\n",
      "Warning: No matching start or end index for trial 136. Skipping trial.\n",
      "Warning: No matching start or end index for trial 137. Skipping trial.\n",
      "Warning: No matching start or end index for trial 138. Skipping trial.\n",
      "Warning: No matching start or end index for trial 139. Skipping trial.\n",
      "Warning: No matching start or end index for trial 144. Skipping trial.\n",
      "Warning: No matching start or end index for trial 146. Skipping trial.\n",
      "Warning: No matching start or end index for trial 149. Skipping trial.\n",
      "Warning: No matching start or end index for trial 150. Skipping trial.\n",
      "Warning: No matching start or end index for trial 151. Skipping trial.\n",
      "Warning: No matching start or end index for trial 160. Skipping trial.\n",
      "Warning: No matching start or end index for trial 166. Skipping trial.\n",
      "Warning: No matching start or end index for trial 168. Skipping trial.\n",
      "Warning: No matching start or end index for trial 169. Skipping trial.\n",
      "Warning: No matching start or end index for trial 170. Skipping trial.\n",
      "Warning: No matching start or end index for trial 181. Skipping trial.\n",
      "Warning: No matching start or end index for trial 182. Skipping trial.\n",
      "Warning: No matching start or end index for trial 184. Skipping trial.\n",
      "Warning: No matching start or end index for trial 190. Skipping trial.\n",
      "Warning: No matching start or end index for trial 191. Skipping trial.\n",
      "Warning: No matching start or end index for trial 198. Skipping trial.\n",
      "Warning: No matching start or end index for trial 199. Skipping trial.\n",
      "Warning: No matching start or end index for trial 200. Skipping trial.\n",
      "Warning: No matching start or end index for trial 203. Skipping trial.\n",
      "Warning: No matching start or end index for trial 204. Skipping trial.\n",
      "Warning: No matching start or end index for trial 207. Skipping trial.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No matching start or end index for trial 217. Skipping trial.\n",
      "Warning: No matching start or end index for trial 225. Skipping trial.\n",
      "Warning: No matching start or end index for trial 228. Skipping trial.\n",
      "Warning: No matching start or end index for trial 229. Skipping trial.\n",
      "Warning: No matching start or end index for trial 231. Skipping trial.\n",
      "Warning: No matching start or end index for trial 234. Skipping trial.\n",
      "Warning: No matching start or end index for trial 239. Skipping trial.\n",
      "Warning: No matching start or end index for trial 240. Skipping trial.\n",
      "Warning: No matching start or end index for trial 242. Skipping trial.\n",
      "Warning: No matching start or end index for trial 246. Skipping trial.\n",
      "Warning: No matching start or end index for trial 247. Skipping trial.\n",
      "Warning: No matching start or end index for trial 248. Skipping trial.\n",
      "Warning: No matching start or end index for trial 249. Skipping trial.\n",
      "Warning: No matching start or end index for trial 250. Skipping trial.\n",
      "Warning: No matching start or end index for trial 252. Skipping trial.\n",
      "Warning: No matching start or end index for trial 254. Skipping trial.\n",
      "Warning: No matching start or end index for trial 255. Skipping trial.\n",
      "Warning: No matching start or end index for trial 257. Skipping trial.\n",
      "Warning: No matching start or end index for trial 268. Skipping trial.\n",
      "Warning: No matching start or end index for trial 270. Skipping trial.\n",
      "Warning: No matching start or end index for trial 273. Skipping trial.\n",
      "Warning: No matching start or end index for trial 274. Skipping trial.\n",
      "Warning: No matching start or end index for trial 276. Skipping trial.\n",
      "Warning: No matching start or end index for trial 279. Skipping trial.\n",
      "Warning: No matching start or end index for trial 282. Skipping trial.\n",
      "Warning: No matching start or end index for trial 283. Skipping trial.\n",
      "Warning: No matching start or end index for trial 284. Skipping trial.\n",
      "Warning: No matching start or end index for trial 287. Skipping trial.\n",
      "Warning: No matching start or end index for trial 289. Skipping trial.\n",
      "Warning: No matching start or end index for trial 295. Skipping trial.\n",
      "Warning: No matching start or end index for trial 303. Skipping trial.\n",
      "Warning: No matching start or end index for trial 307. Skipping trial.\n",
      "Warning: No matching start or end index for trial 312. Skipping trial.\n",
      "Warning: No matching start or end index for trial 313. Skipping trial.\n",
      "Warning: No matching start or end index for trial 327. Skipping trial.\n",
      "Warning: No matching start or end index for trial 328. Skipping trial.\n",
      "Warning: No matching start or end index for trial 330. Skipping trial.\n",
      "Warning: No matching start or end index for trial 331. Skipping trial.\n",
      "Warning: No matching start or end index for trial 336. Skipping trial.\n",
      "Warning: No matching start or end index for trial 339. Skipping trial.\n",
      "Warning: No matching start or end index for trial 341. Skipping trial.\n",
      "Warning: No matching start or end index for trial 352. Skipping trial.\n",
      "Warning: No matching start or end index for trial 355. Skipping trial.\n",
      "Warning: No matching start or end index for trial 356. Skipping trial.\n",
      "Warning: No matching start or end index for trial 357. Skipping trial.\n",
      "Warning: No matching start or end index for trial 358. Skipping trial.\n",
      "Response locked data\n",
      "Downsampled data: (235, 255, 250)\n",
      "defined cond_targets\n",
      "(235, 255, 250)\n",
      "255\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "235 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Resampled data, new shape: (235, 255, 250)\n",
      "Randomized cond_target and its indices\n",
      "randomized trial order within a matrix of trial data\n",
      "Completed setup for decoding, defined train and and test folds\n",
      "fsample\n",
      "['fsample']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file fsample\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/fsample_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "elec\n",
      "['#refs#', 'elec']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/elec_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "hdr\n",
      "['#refs#', 'hdr']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/hdr_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "trialinfo\n",
      "['#refs#', '#subsystem#', 'trialinfo']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file trialinfo\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/trialinfo_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "sampleinfo\n",
      "['sampleinfo']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file sampleinfo\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/sampleinfo_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "trial\n",
      "['#refs#', 'trial']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file trial\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/trial_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "time\n",
      "['#refs#', 'time']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file time\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/time_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "label\n",
      "['#refs#', 'label']\n",
      "Error 'Dataset' object has no attribute 'items' occurred for file label\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/label_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "cfg\n",
      "['#refs#', '#subsystem#', 'cfg']\n",
      "Finished loading /home/let83/FND4/results/preproc1_causalFilter/sub3/cfg_hp0.1notch_seg_autochannelz3_trialz3_ICAz3_baselinelp125avgref.mat\n",
      "Loaded Data\n",
      "Defined trialinfo\n",
      "ERROR could not broadcast input array from shape (2) into shape (3945,255) at a,205!!!\n",
      "\n",
      "Defined trials\n",
      "defined samples\n",
      "Defined time\n",
      "Warning: No matching start or end index for trial 0. Skipping trial.\n",
      "Warning: No matching start or end index for trial 3. Skipping trial.\n",
      "Warning: No matching start or end index for trial 14. Skipping trial.\n",
      "Warning: No matching start or end index for trial 16. Skipping trial.\n",
      "Warning: No matching start or end index for trial 17. Skipping trial.\n",
      "Warning: No matching start or end index for trial 18. Skipping trial.\n",
      "Warning: No matching start or end index for trial 20. Skipping trial.\n",
      "Warning: No matching start or end index for trial 21. Skipping trial.\n",
      "Warning: No matching start or end index for trial 27. Skipping trial.\n",
      "Warning: No matching start or end index for trial 28. Skipping trial.\n",
      "Warning: No matching start or end index for trial 30. Skipping trial.\n",
      "Warning: No matching start or end index for trial 33. Skipping trial.\n",
      "Warning: No matching start or end index for trial 37. Skipping trial.\n",
      "Warning: No matching start or end index for trial 38. Skipping trial.\n",
      "Warning: No matching start or end index for trial 41. Skipping trial.\n",
      "Warning: No matching start or end index for trial 42. Skipping trial.\n",
      "Warning: No matching start or end index for trial 46. Skipping trial.\n",
      "Warning: No matching start or end index for trial 47. Skipping trial.\n",
      "Warning: No matching start or end index for trial 49. Skipping trial.\n",
      "Warning: No matching start or end index for trial 50. Skipping trial.\n",
      "Warning: No matching start or end index for trial 52. Skipping trial.\n",
      "Warning: No matching start or end index for trial 55. Skipping trial.\n",
      "Warning: No matching start or end index for trial 56. Skipping trial.\n",
      "Warning: No matching start or end index for trial 59. Skipping trial.\n",
      "Warning: No matching start or end index for trial 60. Skipping trial.\n",
      "Warning: No matching start or end index for trial 61. Skipping trial.\n",
      "Warning: No matching start or end index for trial 62. Skipping trial.\n",
      "Warning: No matching start or end index for trial 63. Skipping trial.\n",
      "Warning: No matching start or end index for trial 64. Skipping trial.\n",
      "Warning: No matching start or end index for trial 65. Skipping trial.\n",
      "Warning: No matching start or end index for trial 66. Skipping trial.\n",
      "Warning: No matching start or end index for trial 69. Skipping trial.\n",
      "Warning: No matching start or end index for trial 71. Skipping trial.\n",
      "Warning: No matching start or end index for trial 72. Skipping trial.\n",
      "Warning: No matching start or end index for trial 76. Skipping trial.\n",
      "Warning: No matching start or end index for trial 80. Skipping trial.\n",
      "Warning: No matching start or end index for trial 83. Skipping trial.\n",
      "Warning: No matching start or end index for trial 85. Skipping trial.\n",
      "Warning: No matching start or end index for trial 86. Skipping trial.\n",
      "Warning: No matching start or end index for trial 89. Skipping trial.\n",
      "Warning: No matching start or end index for trial 90. Skipping trial.\n",
      "Warning: No matching start or end index for trial 91. Skipping trial.\n",
      "Warning: No matching start or end index for trial 92. Skipping trial.\n",
      "Warning: No matching start or end index for trial 99. Skipping trial.\n",
      "Warning: No matching start or end index for trial 101. Skipping trial.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No matching start or end index for trial 110. Skipping trial.\n",
      "Warning: No matching start or end index for trial 111. Skipping trial.\n",
      "Warning: No matching start or end index for trial 113. Skipping trial.\n",
      "Warning: No matching start or end index for trial 119. Skipping trial.\n",
      "Warning: No matching start or end index for trial 122. Skipping trial.\n",
      "Warning: No matching start or end index for trial 123. Skipping trial.\n",
      "Warning: No matching start or end index for trial 124. Skipping trial.\n",
      "Warning: No matching start or end index for trial 125. Skipping trial.\n",
      "Warning: No matching start or end index for trial 126. Skipping trial.\n",
      "Warning: No matching start or end index for trial 127. Skipping trial.\n",
      "Warning: No matching start or end index for trial 130. Skipping trial.\n",
      "Warning: No matching start or end index for trial 132. Skipping trial.\n",
      "Warning: No matching start or end index for trial 138. Skipping trial.\n",
      "Warning: No matching start or end index for trial 139. Skipping trial.\n",
      "Warning: No matching start or end index for trial 141. Skipping trial.\n",
      "Warning: No matching start or end index for trial 143. Skipping trial.\n",
      "Warning: No matching start or end index for trial 144. Skipping trial.\n",
      "Warning: No matching start or end index for trial 146. Skipping trial.\n",
      "Warning: No matching start or end index for trial 148. Skipping trial.\n",
      "Warning: No matching start or end index for trial 149. Skipping trial.\n",
      "Warning: No matching start or end index for trial 153. Skipping trial.\n",
      "Warning: No matching start or end index for trial 156. Skipping trial.\n",
      "Warning: No matching start or end index for trial 158. Skipping trial.\n",
      "Warning: No matching start or end index for trial 163. Skipping trial.\n",
      "Warning: No matching start or end index for trial 164. Skipping trial.\n",
      "Warning: No matching start or end index for trial 168. Skipping trial.\n",
      "Warning: No matching start or end index for trial 169. Skipping trial.\n",
      "Warning: No matching start or end index for trial 170. Skipping trial.\n",
      "Warning: No matching start or end index for trial 173. Skipping trial.\n",
      "Warning: No matching start or end index for trial 174. Skipping trial.\n",
      "Warning: No matching start or end index for trial 181. Skipping trial.\n",
      "Warning: No matching start or end index for trial 182. Skipping trial.\n",
      "Warning: No matching start or end index for trial 183. Skipping trial.\n",
      "Warning: No matching start or end index for trial 185. Skipping trial.\n",
      "Warning: No matching start or end index for trial 192. Skipping trial.\n",
      "Warning: No matching start or end index for trial 193. Skipping trial.\n",
      "Warning: No matching start or end index for trial 194. Skipping trial.\n",
      "Warning: No matching start or end index for trial 196. Skipping trial.\n",
      "Warning: No matching start or end index for trial 200. Skipping trial.\n",
      "Warning: No matching start or end index for trial 202. Skipping trial.\n",
      "Warning: No matching start or end index for trial 203. Skipping trial.\n",
      "Warning: No matching start or end index for trial 205. Skipping trial.\n",
      "Warning: No matching start or end index for trial 206. Skipping trial.\n",
      "Warning: No matching start or end index for trial 207. Skipping trial.\n",
      "Warning: No matching start or end index for trial 212. Skipping trial.\n",
      "Warning: No matching start or end index for trial 214. Skipping trial.\n",
      "Warning: No matching start or end index for trial 219. Skipping trial.\n",
      "Warning: No matching start or end index for trial 225. Skipping trial.\n",
      "Warning: No matching start or end index for trial 228. Skipping trial.\n",
      "Warning: No matching start or end index for trial 230. Skipping trial.\n",
      "Warning: No matching start or end index for trial 233. Skipping trial.\n",
      "Warning: No matching start or end index for trial 234. Skipping trial.\n",
      "Warning: No matching start or end index for trial 235. Skipping trial.\n",
      "Warning: No matching start or end index for trial 237. Skipping trial.\n",
      "Warning: No matching start or end index for trial 240. Skipping trial.\n",
      "Warning: No matching start or end index for trial 242. Skipping trial.\n",
      "Warning: No matching start or end index for trial 243. Skipping trial.\n",
      "Warning: No matching start or end index for trial 244. Skipping trial.\n",
      "Warning: No matching start or end index for trial 245. Skipping trial.\n",
      "Warning: No matching start or end index for trial 247. Skipping trial.\n",
      "Warning: No matching start or end index for trial 248. Skipping trial.\n",
      "Warning: No matching start or end index for trial 249. Skipping trial.\n",
      "Warning: No matching start or end index for trial 254. Skipping trial.\n",
      "Warning: No matching start or end index for trial 255. Skipping trial.\n",
      "Warning: No matching start or end index for trial 258. Skipping trial.\n",
      "Warning: No matching start or end index for trial 259. Skipping trial.\n",
      "Warning: No matching start or end index for trial 263. Skipping trial.\n",
      "Warning: No matching start or end index for trial 265. Skipping trial.\n",
      "Warning: No matching start or end index for trial 266. Skipping trial.\n",
      "Warning: No matching start or end index for trial 267. Skipping trial.\n",
      "Warning: No matching start or end index for trial 269. Skipping trial.\n",
      "Warning: No matching start or end index for trial 270. Skipping trial.\n",
      "Warning: No matching start or end index for trial 275. Skipping trial.\n",
      "Warning: No matching start or end index for trial 276. Skipping trial.\n",
      "Warning: No matching start or end index for trial 279. Skipping trial.\n",
      "Warning: No matching start or end index for trial 282. Skipping trial.\n",
      "Warning: No matching start or end index for trial 284. Skipping trial.\n",
      "Warning: No matching start or end index for trial 288. Skipping trial.\n",
      "Warning: No matching start or end index for trial 289. Skipping trial.\n",
      "Warning: No matching start or end index for trial 290. Skipping trial.\n",
      "Warning: No matching start or end index for trial 295. Skipping trial.\n",
      "Warning: No matching start or end index for trial 300. Skipping trial.\n",
      "Warning: No matching start or end index for trial 304. Skipping trial.\n",
      "Warning: No matching start or end index for trial 305. Skipping trial.\n",
      "Warning: No matching start or end index for trial 307. Skipping trial.\n",
      "Warning: No matching start or end index for trial 308. Skipping trial.\n",
      "Warning: No matching start or end index for trial 309. Skipping trial.\n",
      "Warning: No matching start or end index for trial 311. Skipping trial.\n",
      "Warning: No matching start or end index for trial 313. Skipping trial.\n",
      "Warning: No matching start or end index for trial 314. Skipping trial.\n",
      "Warning: No matching start or end index for trial 317. Skipping trial.\n",
      "Warning: No matching start or end index for trial 319. Skipping trial.\n",
      "Warning: No matching start or end index for trial 320. Skipping trial.\n",
      "Warning: No matching start or end index for trial 321. Skipping trial.\n",
      "Warning: No matching start or end index for trial 322. Skipping trial.\n",
      "Warning: No matching start or end index for trial 323. Skipping trial.\n",
      "Warning: No matching start or end index for trial 324. Skipping trial.\n",
      "Warning: No matching start or end index for trial 325. Skipping trial.\n",
      "Warning: No matching start or end index for trial 328. Skipping trial.\n",
      "Warning: No matching start or end index for trial 329. Skipping trial.\n",
      "Warning: No matching start or end index for trial 333. Skipping trial.\n",
      "Warning: No matching start or end index for trial 334. Skipping trial.\n",
      "Warning: No matching start or end index for trial 335. Skipping trial.\n",
      "Warning: No matching start or end index for trial 336. Skipping trial.\n",
      "Warning: No matching start or end index for trial 338. Skipping trial.\n",
      "Warning: No matching start or end index for trial 339. Skipping trial.\n",
      "Warning: No matching start or end index for trial 340. Skipping trial.\n",
      "Warning: No matching start or end index for trial 341. Skipping trial.\n",
      "Warning: No matching start or end index for trial 344. Skipping trial.\n",
      "Warning: No matching start or end index for trial 345. Skipping trial.\n",
      "Warning: No matching start or end index for trial 347. Skipping trial.\n",
      "Warning: No matching start or end index for trial 348. Skipping trial.\n",
      "Warning: No matching start or end index for trial 353. Skipping trial.\n",
      "Warning: No matching start or end index for trial 354. Skipping trial.\n",
      "Response locked data\n",
      "Downsampled data: (201, 255, 250)\n",
      "defined cond_targets\n",
      "(201, 255, 250)\n",
      "255\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "201 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Resampled data, new shape: (201, 255, 250)\n",
      "Randomized cond_target and its indices\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 256 is out of bounds for axis 0 with size 201",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6bfda01f7c2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubjNum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrandom_data_trl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnTimepoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoderType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassify_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingAcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hand'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DecodingAccuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Write function to run Subject decoding in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_decoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-5a412e23f2b5>\u001b[0m in \u001b[0;36mDecodingAcc\u001b[0;34m(classify_cond, decoderType, subjNum, decodingAnalysis)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mrandom_data_trl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_cond_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnTimepoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxx_cond_inds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mtrlData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_trl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# pull trial data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mrandom_data_trl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrlData\u001b[0m   \u001b[0;31m# final shape = (319, 251, 250)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'randomized trial order within a matrix of trial data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 256 is out of bounds for axis 0 with size 201"
     ]
    }
   ],
   "source": [
    "# #Subject list\n",
    "# subjects = [1, 2, 3, 10, 16, 17, 21, 34, 44]\n",
    "# for subjNum in subjects:\n",
    "#     random_data_trl, folds_mat, nTimepoints, decoderType, classify_cond, subjNum = DecodingAcc('Hand', 'SVM', subjNum, 'DecodingAccuracy')\n",
    "#     RunDecoders(random_data_trl, folds_mat, nTimepoints, decoderType, classify_cond, subjNum)\n",
    "# # Write function to run Subject decoding in parallel\n",
    "# def run_decoding(subjNum):\n",
    "#     return RunDecoders(random_data_trl, folds_mat, nTimepoints, decoderType, classify_cond, subjNum)\n",
    "\n",
    "# # Actually run in parallel using ProcessPoolExecutor (used for more heavy duty function runing)\n",
    "# results = []\n",
    "# with ProcessPoolExecutor() as executor:\n",
    "#     futures = {executor.submit(run_decoding, subj): subj for subj in subjects}\n",
    "    \n",
    "#     for future in as_completed(futures):\n",
    "#         subj = futures[future]\n",
    "#         try:\n",
    "#             result = future.result()\n",
    "#             results.append((subj, result))\n",
    "#         except Exception as e:\n",
    "#             print(f\"Subject {subj} failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e5d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eeg_decoding_env)",
   "language": "python",
   "name": "eeg_decoding_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
